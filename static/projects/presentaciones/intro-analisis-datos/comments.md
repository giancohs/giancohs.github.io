# SLIDE 1. Introducción al análisis de datos
¿Cómo utilizar las hojas de cálculo para mis investigaciones periodísticas?

Comentarios:
Buenas tardes a todos y todas. Mi nombre es Gianfranco Huamán, periodista y analista de datos de OjoPúblico. Bienvenidos nuevamente a este taller. Hoy, vamos a explorar cómo las hojas de cálculo pueden convertirse en una herramienta poderosa para sus investigaciones periodísticas. Espero que esta sesión les sea de utilidadl.

# SLIDE 2. ¿Qué es una hoja de cálculo?

Comentarios:
Probablemente han estado como yo cuando crean un archivo en excel o en google y se encuentra con esto: (una imagen de una hoja de cálculo vacía con un signo de interrogación)

¿Y ahora qué? ¿Qué hago aquí? ¿Cómo se llena la información? ¿Los datos? ¿Fórmulas? ¿Cómo hago el filtro o las tablas dinámicas?

Empecemos definiendo el término “hoja de cálculo”. ¿Qué es? ¿Qué significa? Es lo mismo que una tabla, base de datos, dataset, data, son sinónimos?

Entonces, estrictamente, una hoja de cálculo es una herramienta digital que nos permite almacenar, organizar y manipular datos. A veces se confunde con bases de datos y datasets, una hoja de cálculo es más versátil. Puede contener fórmulas, gráficos y una variedad de tipos de datos, mientras que un dataset es generalmente sólo un conjunto de datos crudos.

# SLIDE 3. ¿En qué momento me sirve crear una hoja de cálculo?

Para casi todo, pero depende del tipo de historia que estás contando y el tiempo que tienes disponible.
Ojo. El análisis de datos no reemplaza el reporteo tradicional.
Es necesario en la actualidad; cada día, el Estado y diversas organizaciones generan grandes cantidades de información digitalizada a la que el ciudadano común no accede o no le interesa. Nuestra labor es procesar esta información y contarla de la forma más simple.

Comentarios
Ahora que sabemos qué significa una hoja de cálculo. Ahora ¿En qué situaciones puedo usar/crear una hoja de cálculo y para luego realizar el respectivo análisis?

Para casi todo, pero depende del tipo de historia que estás contando y el tiempo que tienes disponible.
Por ejemplo, no es lo mismo un reportaje a largo plazo, que una nota de coyuntura que debes cerrar en días o máximo una semana. Para ambos casos puedes usar las hojas de cálculo para analizar datos, pero hay que saber priorizar.
Ojo. El análisis de datos no reemplaza el reporteo tradicional.
Si bien en OjoPúblico se promueve mucho el uso del análisis de datos, no significa que reemplace el reporteo de calle. Podría decirse que las hojas de cálculo son una fuente más, al igual que un documento oficial, una investigación científica, un especialista. En el periodismo lo óptimo es la variedad de fuentes y puntos de vista. 
Usar hojas de cálculo es casi necesario en la actualidad, cada día el Estado y organizaciones generan mucha información digitalizada y que el ciudadano de pie no accede o no le interesa. Nuestra labor es procesar esta información, contrastar, y contarla de la forma más simple. 
Solo en el portal de datos abiertos existen más de 7000 mil conjuntos de datos descargables. De estos, 1200 son únicamente excels/hojas de cálculo.

# SLIDE 4. ¿Por dónde empiezo?

¿Toda la información se puede estructurar? ¿Qué tipo de información se puede analizar?

Comentarios:

Una de las primeras preguntas que debemos hacernos es si la información que tenemos se puede estructurar para su análisis. No todos los datos son iguales y la forma en que los recibimos también varía. Pongamos algunos ejemplos.

Si recibes un PDF con una tabla, tienes un problema de accesibilidad. Los datos están allí, pero están atrapados en un formato que no es fácilmente analizable. Hay herramientas y software que pueden convertir estas tablas en PDF a un formato más manejable como CSV o Excel. Pero ten en cuenta que este proceso puede requerir un tiempo de limpieza adicional para asegurarse de que los datos se hayan convertido correctamente.

Si te mandan un correo con un archivo de Excel, podrías pensar que está listo para analizar. Pero espera, ¿has revisado la calidad de esos datos? ¿Están completos, son coherentes, están en el formato correcto? A menudo, incluso los archivos de Excel que parecen estar "listos para usar" requieren un grado de limpieza y preparación.

¿Y qué hay de las hojas de cálculo que genera el Estado? No es raro encontrar que la información pública tiene problemas de formato, datos incompletos o incluso errores. Antes de sumergirte en el análisis, es crucial revisar estos aspectos. Por ejemplo, en el caso de los datos abiertos de IRTP, podrías encontrar que las fechas están en diferentes formatos o que hay campos con información faltante o irrelevante que necesitan ser depurados.

La clave aquí es entender que la calidad de la información digital que recibimos puede variar significativamente. Por eso, siempre debemos estimar cuánto tiempo y esfuerzo nos va a tomar preparar esos datos para su análisis. Tener un proceso claro y estructurado para el análisis de datos te ayudará a hacer estas estimaciones de manera más precisa.

# SLIDE 5. Etapas del análisis de datos
Recolección
Procesamiento
Limpieza
Análisis
Comunicación
Comentarios:

El análisis de datos es un proceso que generalmente podemos dividir en cinco etapas clave. Aunque algunos podrían desagregarlo en más pasos, el consenso es que estos son los más fundamentales:

	Recolección de Datos: La primera etapa es cómo y de dónde obtienes la información. Puede ser a través de una filtración confidencial, solicitudes de acceso a la información a entidades gubernamentales, descargas desde portales de datos en internet, boletines estadísticos, informes académicos, entre otros. Esta etapa es crucial porque define la base sobre la cual se realizará todo el análisis posterior.

	Procesamiento: Aquí se trata de preparar los datos para el análisis. En algunos casos, como cuando recibes un archivo de Excel bien estructurado, podrías saltarte este paso. Pero en otros casos, como cuando la información llega en un PDF o incluso en un montón de documentos físicos, hay que "procesar" estos datos para convertirlos en un formato analizable. Esto podría implicar el uso de software OCR para extraer texto de PDFs o la entrada manual de datos en una hoja de cálculo.

	Limpieza: Una vez que los datos están en un formato que la computadora puede entender, el siguiente paso es la limpieza. Esto implica eliminar o corregir errores tipográficos, estandarizar nombres y categorías, arreglar formatos de fechas y números, entre otras cosas. No subestimes esta etapa; un buen análisis necesita datos limpios.

	Análisis: Con los datos limpios en mano, ahora puedes proceder al análisis como tal. Este es el momento para realizar análisis exploratorios para entender las características de tus datos, identificar patrones, outliers, etc. Aquí también podrás aplicar modelos estadísticos, hacer cálculos y usar herramientas como tablas dinámicas para resumir la información.

	Comunicación: Finalmente, una vez que has sacado conclusiones de tus datos, tienes que comunicarlos. Esto puede hacerse de muchas maneras: incluyendo los hallazgos en el texto de un artículo, creando visualizaciones gráficas, construyendo infografías o incluso mediante presentaciones interactivas en línea. El método que elijas dependerá del tipo de historia que estás contando y de los recursos que tengas a disposición.

Es importante notar que puedes realizar todas estas etapas con una sola herramienta como Excel, o usar una combinación de herramientas más especializadas dependiendo de tus necesidades y habilidades. En OjoPúblico, usamos una variedad de herramientas para diferentes propósitos, y más adelante en esta presentación, les daremos un recorrido por algunas de ellas. Pero por ahora, entender estos cinco pasos básicos ya les da una buena base para empezar a trabajar en análisis de datos.

#SLIDE 6. Herramientas para analizar datos

Comentarios:
El análisis de datos puede llevarse a cabo con diversas herramientas que varían en complejidad, coste y funcionalidades. Aquí describo algunas de las más comunes, cada una con sus respectivas ventajas y desventajas:
- Microsoft Excel
 - Ventajas:
   - Es ampliamente utilizado y conocido, lo que facilita su adopción.
   - Tiene una curva de aprendizaje relativamente rápida.
   - Ofrece diversas opciones para visualización de datos y tablas dinámicas.
   - Apto para datasets pequeños y medianos, manejando desde 1 hasta aproximadamente 1 millón de filas.
  - Desventajas:
   - Es una herramienta de pago.
   - No es ideal para el trabajo colaborativo en tiempo real.
   - Algunas funciones avanzadas pueden requerir el uso de lenguaje VBA, lo cual puede complicar su uso.
- Open Refine
 - Ventajas:
   - Especializado en limpieza y transformación de datos.
   - Permite el manejo de datos desordenados o inconsistentes.
 - Desventajas:
   - Menos funcionalidades para análisis y visualización en comparación con otras herramientas.
   - Curva de aprendizaje moderada.
- R / RStudio - Python / Pandas
 - Ventajas:
   - Son de código abierto y gratuitos.
   - Ofrecen un conjunto completo de herramientas para limpieza, análisis y visualización de datos.
   - Posibilidad de cruzar diferentes bases de datos, hacer visualizaciones avanzadas y mapas.
   - Son altamente personalizables y permiten automatizar procesos mediante scripts.
   - Adecuados para big data y datasets grandes, pudiendo manejar millones de filas.
 - Desventajas:
   - Son complejos y tienen una curva de aprendizaje más empinada.
   - Requieren un interés y conocimiento sólido en programación.
- Google Sheets / Hojas de cálculo de Google
 - Ventajas:
   - Acceso y colaboración en tiempo real al estar alojado en la nube.
   - Apto para datasets pequeños y medianos, con un límite de aproximadamente 250,000 filas.
   - Ofrece opciones para visualizaciones y tablas dinámicas.
   - Curva de aprendizaje rápida y fácil de usar.
- Desventajas:
   - Menos potente en términos de funcionalidades en comparación con otras herramientas más especializadas.
   - Limitado a datasets de tamaño medio, con un tope de aproximadamente 250,000 filas.

# SLIDE 7. Demostración Ejercicio práctico

Analizar datos sobre Penalidades y multas a contratistas del Estado - Organismo Supervisor de Contrataciones del Estado (OSCE). Descargar dataset aquí
- ¿Cuáles son las empresas con mayores multas?
- ¿Cuáles son las entidades públicas que más multan?
- ¿Cuántas multas se han registrado en los últimos 5 años?
- ¿Cuáles son los tipos de multas más comunes?

Comentarios:
Ahora que ya hemos cubierto las bases del análisis de datos y las herramientas que podemos usar, vamos a realizar un ejercicio práctico para consolidar lo aprendido. El tema que abordaremos es muy relevante: las penalidades y multas a contratistas del Estado, un dataset que podemos descargar desde el portal de datos abiertos.

- ¿Cuáles son las empresas con mayores multas?
 - Para responder a esta pregunta, vamos a realizar un filtrado de datos por el campo que identifica a la empresa y luego sumaremos las multas asociadas a cada una. Podemos usar una tabla dinámica para hacer esto de forma rápida y sencilla.
- ¿Cuáles son las entidades públicas que más multan?
 - Similar al punto anterior, pero esta vez nos enfocaremos en las entidades públicas que emiten las multas. Esto nos dará una idea de qué organismos son más estrictos en el cumplimiento de contratos.
- ¿Cuántas multas se han registrado en los últimos 5 años?
 - Contaremos el número de registros por año..
- ¿Cuáles son los tipos de multas más comunes?
 - Finalmente, vamos a explorar la diversidad en los tipos de multas aplicadas. Esto nos puede dar una idea sobre cuáles son las infracciones más comunes y, por ende, dónde podrían estar los mayores problemas en el proceso de contratación pública.

Este ejercicio nos ayudará a entender mejor cómo aplicar las etapas del análisis de datos en un caso práctico y real. Utilizaremos principalmente hojas de cálculo para este ejercicio, pero recuerden que las técnicas aprendidas son aplicables en herramientas más avanzadas como R o Python, según se requiera.


# SLIDE 8. Pasos a seguir

Preparar nuestro entorno de trabajo
Crear una cuenta de Google (Si no tienes una).
Crear una carpeta con el nombre de nuestro proyecto. “Penalidades OSCE”.
Recolección
Descargamos el dataset y lo subimos a nuestra carpeta de Google Drive.
Procesamiento y limpieza
Importamos el dataset a Google Sheets.
Comprobamos el formato numérico de nuestro archivo. (Separadores de miles y decimales).
Comprobamos que los datos estén en el formato correcto. (Fechas, números, texto).
Creamos nuevas columnas para analizar la información.
Podemos usar filtros para hacer una revisión rápida, y también ayuda en la limpieza.
Limpiamos caracteres extraños o números. Podemos usar la herramienta “Buscar y reemplazar”
Comprobamos que no existan duplicados.
Análisis
Creamos tabla dinámica
Comunicación
Creamos visualizaciones
Redactamos un texto con los hallazgos

Comentarios:
Este es un resumen de los pasos que vamos a seguir en nuestro ejercicio práctico. Comenzaremos preparando todo lo necesario en nuestro entorno de trabajo. Esto incluye tener una cuenta de Google y una carpeta específica para este proyecto.

Luego, vamos a descargar el dataset y empezar con la fase de procesamiento y limpieza de datos, que como hemos visto, es crucial para cualquier análisis de datos. Aquí utilizaremos Google Sheets, pero los pasos son aplicables a otras herramientas.

En la fase de análisis, la tabla dinámica será nuestra principal herramienta para examinar los datos desde diferentes ángulos y responder a nuestras preguntas de investigación.

Finalmente, en la fase de comunicación, vamos a aprender cómo presentar nuestros hallazgos de manera efectiva, utilizando tanto visualizaciones como texto escrito.

Estos pasos son una guía general y pueden adaptarse según las necesidades específicas de cada proyecto. Lo importante es mantener un flujo de trabajo organizado para asegurar la calidad y precisión en cada etapa del análisis.

Si bien no van a poder realizar el paso a paso conmigo, van a poder observar y tener una mejor idea cómo sería trabajar con datos de un tamaño mediano.

Link a datos:

https://drive.google.com/drive/u/0/folders/1Wd0U84KAQstFzdfWfUvoizvSkOlfLTK2


 


